# ğŸ’¬ Chatbot iTributos

Sistema de consulta inteligente ao banco de dados iTributos usando IA (Google Gemini ou Ollama) para converter perguntas em linguagem natural para SQL.

## ğŸ¯ Funcionalidades

- âœ… **Consultas em linguagem natural** - FaÃ§a perguntas como "histÃ³rico do contribuinte X"
- ğŸ¤– **Dois provedores de IA**:
  - **Google Gemini** (gratuito, 15 req/min)
  - **Ollama** (local, offline)
- ğŸ’¾ **Cache inteligente** - Respostas rÃ¡pidas para consultas repetidas
- ğŸ“Š **VisualizaÃ§Ã£o de dados** - Tabelas e grÃ¡ficos interativos
- ğŸ“¥ **ExportaÃ§Ã£o** - Download de resultados em CSV
- ğŸ” **SQL transparente** - Veja a query gerada
- ğŸ“ˆ **HistÃ³rico** - Acompanhe suas consultas

## ğŸš€ InstalaÃ§Ã£o

### 1. Requisitos

- Python 3.10+
- PostgreSQL (banco iTributos configurado)
- ConexÃ£o com internet (para Gemini) OU Ollama instalado (para uso offline)

### 2. Instalar dependÃªncias

```powershell
cd C:\Users\Fiscal\PROJETOS\mcp.local\chatbot_itributos

# Ativar ambiente virtual
..\.venv\Scripts\Activate.ps1

# Instalar pacotes
pip install -r requirements.txt
```

### 3. Configurar API Key do Google Gemini (RECOMENDADO)

#### Obter API Key (Gratuita):
1. Acesse: https://aistudio.google.com/app/apikey
2. FaÃ§a login com conta Google
3. Clique em "Create API Key"
4. Copie a chave gerada

#### Configurar no projeto:
A chave jÃ¡ estÃ¡ configurada no arquivo `.env`:
```
GOOGLE_API_KEY=AIzaSyCq_xGXfc05bNrOOOa3VWaeynKwptQeHfo
```

### 4. (OPCIONAL) Instalar Ollama para uso offline

Se preferir usar IA local sem depender de internet:

1. Baixe: https://ollama.ai
2. Instale o Ollama
3. Baixe um modelo:
```powershell
ollama pull llama3.1
```

4. Altere no arquivo `.env`:
```
LLM_PROVIDER=ollama
```

## â–¶ï¸ Como Usar

### Iniciar o chatbot:

```powershell
# Certifique-se de estar no diretÃ³rio correto
cd C:\Users\Fiscal\PROJETOS\mcp.local\chatbot_itributos

# Ativar ambiente virtual
..\.venv\Scripts\Activate.ps1

# Executar aplicaÃ§Ã£o
streamlit run app.py
```

A aplicaÃ§Ã£o abrirÃ¡ automaticamente no navegador em: `http://localhost:8501`

### Alternar entre Gemini e Ollama:

Na barra lateral esquerda, vocÃª pode alternar entre os provedores:
- ğŸŒ **Gemini**: API Google (requer internet, gratuito)
- ğŸ  **Ollama**: Local (offline, requer instalaÃ§Ã£o)

## ğŸ’¡ Exemplos de Perguntas

### HistÃ³rico de Contribuinte
```
Me dÃª um histÃ³rico financeiro completo do contribuinte 34.019.100/0001-81
```

### Parcelamentos
```
Quais sÃ£o todos os parcelamentos ativos?
Mostre parcelamentos com reparcelamento do contribuinte X
```

### Pagamentos
```
Mostre os pagamentos realizados em dezembro de 2024
Quais dÃ©bitos estÃ£o em aberto?
```

### DÃ­vida Ativa
```
Contribuintes com dÃ©bitos em dÃ­vida ativa
```

### AnÃ¡lises
```
Total arrecadado por tipo de receita em 2024
Contribuintes inadimplentes com mais de 3 parcelas atrasadas
```

## ğŸ“ Estrutura do Projeto

```
chatbot_itributos/
â”œâ”€â”€ app.py                 # Interface Streamlit (main)
â”œâ”€â”€ config.py              # ConfiguraÃ§Ãµes e variÃ¡veis de ambiente
â”œâ”€â”€ database.py            # ConexÃ£o e operaÃ§Ãµes no PostgreSQL
â”œâ”€â”€ llm_service.py         # IntegraÃ§Ã£o com Gemini/Ollama
â”œâ”€â”€ cache_manager.py       # Sistema de cache
â”œâ”€â”€ requirements.txt       # DependÃªncias Python
â”œâ”€â”€ .env                   # VariÃ¡veis de ambiente (com API key configurada)
â”œâ”€â”€ .env.example           # Exemplo de configuraÃ§Ã£o
â””â”€â”€ cache/                 # DiretÃ³rio de cache (criado automaticamente)
```

## âš™ï¸ ConfiguraÃ§Ãµes

Edite o arquivo `.env` para personalizar:

```bash
# Banco de Dados
DB_HOST=localhost
DB_PORT=5432
DB_NAME=itributos
DB_USER=postgres
DB_PASSWORD=postgres

# Google Gemini (JÃ CONFIGURADO)
GOOGLE_API_KEY=AIzaSyCq_xGXfc05bNrOOOa3VWaeynKwptQeHfo

# Ollama (para uso local)
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=llama3.2

# Escolha o provedor: 'ollama'
LLM_PROVIDER=ollama

# Cache (1 hora = 3600 segundos)
CACHE_TTL_SECONDS=3600
```

## ğŸ”§ Troubleshooting

### Erro: "GOOGLE_API_KEY nÃ£o configurada"
- Verifique se o arquivo `.env` existe
- A API key jÃ¡ estÃ¡ configurada: `AIzaSyCq_xGXfc05bNrOOOa3VWaeynKwptQeHfo`

### Erro: "NÃ£o foi possÃ­vel conectar ao Ollama"
- Certifique-se de que o Ollama estÃ¡ rodando
- Execute: `ollama serve` em outro terminal
- Baixe o modelo: `ollama pull llama3.1`

### Erro de conexÃ£o com PostgreSQL
- Verifique se o PostgreSQL estÃ¡ rodando
- Confirme credenciais no arquivo `.env`
- Teste conexÃ£o: `psql -U postgres -d itributos`

### Query SQL incorreta
- O LLM pode gerar SQL invÃ¡lido ocasionalmente
- Tente reformular a pergunta de forma mais especÃ­fica
- Use exemplos de perguntas fornecidos como referÃªncia

## ğŸ“Š Limites e Performance

### Google Gemini (Gratuito):
- âœ… 15 requisiÃ§Ãµes/minuto
- âœ… 1.500 requisiÃ§Ãµes/dia
- âœ… Sem necessidade de GPU
- âš ï¸ Requer conexÃ£o com internet

### Ollama (Local):
- âœ… Ilimitado
- âœ… Offline
- âœ… Privacidade total
- âš ï¸ Requer 8GB+ RAM
- âš ï¸ GPU recomendada para melhor performance

### Cache:
- Consultas idÃªnticas retornam instantaneamente do cache
- TTL padrÃ£o: 1 hora
- Cache pode ser limpo manualmente na interface

## ğŸ›¡ï¸ SeguranÃ§a

- âš ï¸ **Nunca compartilhe sua GOOGLE_API_KEY publicamente**
- âœ… Adicione `.env` ao `.gitignore`
- âœ… Use `.env.example` para documentar configuraÃ§Ãµes sem expor credenciais
- âœ… O banco Ã© acessado apenas em modo leitura (SELECT)

## ğŸ“ PrÃ³ximas Melhorias

- [ ] Suporte a mÃºltiplos bancos
- [ ] HistÃ³rico persistente de conversas
- [ ] SugestÃµes automÃ¡ticas de perguntas
- [ ] Export para Excel com formataÃ§Ã£o
- [ ] AutenticaÃ§Ã£o de usuÃ¡rios
- [ ] API REST para integraÃ§Ã£o

## ğŸ“ Suporte

Para dÃºvidas ou problemas:
1. Verifique a seÃ§Ã£o de **Troubleshooting**
2. Consulte os logs no terminal
3. Revise as configuraÃ§Ãµes do `.env`

## ğŸ“„ LicenÃ§a

Uso interno - Prefeitura

---

**Desenvolvido para o setor de FiscalizaÃ§Ã£o TributÃ¡ria** ğŸ’°ğŸ›ï¸
